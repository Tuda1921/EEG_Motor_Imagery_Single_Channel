{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Bidirectional, Dropout\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "df = pd.read_csv('dataC3.csv')\n",
    "# Với cột cuối là nhãn\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T12:48:34.200398Z",
     "start_time": "2024-05-22T12:48:22.467459Z"
    }
   },
   "id": "ae0a54ea67c75115",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# One-hot encoding cho nhãn\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y = encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# K-fold cross-validation\n",
    "kfold = KFold(n_splits=5)\n",
    "fold_scores = []\n",
    "\n",
    "# Tạo thư mục để lưu các plot và mô hình\n",
    "model_dir = 'models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Danh sách để lưu tên file của các mô hình đã train\n",
    "model_filenames = []\n",
    "\n",
    "# Tạo DataFrame để lưu history của loss và accuracy\n",
    "history_df = pd.DataFrame(columns=['fold', 'epoch', 'train_loss', 'test_loss', 'train_accuracy', 'test_accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T10:25:37.511870Z",
     "start_time": "2024-05-21T10:25:37.413638Z"
    }
   },
   "id": "a6d0a427cc75fc86",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[ 0.22027051,  0.40022461,  0.16577296, ..., -0.12085386,\n         -0.16462238, -0.10885405],\n        [ 0.04403516, -0.05445208, -0.74253486, ...,  0.124518  ,\n          0.62695137,  0.72130362],\n        [ 0.07607795, -0.02197518, -0.16886677, ..., -0.02270511,\n         -0.47155915, -0.36929568],\n        ...,\n        [-1.20563364, -1.23985918, -1.28433251, ...,  0.10815988,\n          0.23924178,  0.24925318],\n        [ 0.62080538,  0.36774771,  0.22951386, ...,  0.20630862,\n          0.40078744,  0.4445844 ],\n        [ 0.68489096,  0.61132451,  0.61195926, ..., -0.61159758,\n         -0.73003221, -0.74368051]]),\n array([[1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        ...,\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.]]),\n (6768, 655),\n (6768, 3))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Chia thành tập huấn luyện và tập kiểm tra\n",
    "# time_steps = 80\n",
    "# n_features = X.shape[1]\n",
    "# \n",
    "# # Chuẩn bị đầu vào và đầu ra cho mô hình Bi-LSTM\n",
    "# def prepare_data(data, labels, time_steps):\n",
    "#     X = []\n",
    "#     y = []\n",
    "#     for j in range(len(data)):\n",
    "#         for i in range(0,data.shape[1] - time_steps,40):  # Duyệt theo các cột\n",
    "#             X.append(data[j, i:i+time_steps])\n",
    "#             y.append(labels[j])\n",
    "#             # print(labels[j])\n",
    "#     return np.array(X), np.array(y)\n",
    "# X_,Y_ = prepare_data(X, y, time_steps)\n",
    "# # print(y)\n",
    "# X_,Y_,X_.shape,Y_.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T10:50:44.974196Z",
     "start_time": "2024-05-21T10:50:44.937725Z"
    }
   },
   "id": "ecaf853b8c8b489e",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tuda\\anaconda3\\envs\\EMI\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 40ms/step - accuracy: 0.3203 - loss: 3.4581 - val_accuracy: 0.3575 - val_loss: 3.3825\n",
      "Epoch 2/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.3725 - loss: 3.3734 - val_accuracy: 0.3390 - val_loss: 3.3408\n",
      "Epoch 3/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.4131 - loss: 3.2869 - val_accuracy: 0.3235 - val_loss: 3.2967\n",
      "Epoch 4/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.4352 - loss: 3.2209 - val_accuracy: 0.3102 - val_loss: 3.2547\n",
      "Epoch 5/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.4528 - loss: 3.1555 - val_accuracy: 0.2925 - val_loss: 3.2118\n",
      "Epoch 6/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.4599 - loss: 3.0942 - val_accuracy: 0.2858 - val_loss: 3.1703\n",
      "Epoch 7/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.4767 - loss: 3.0340 - val_accuracy: 0.2829 - val_loss: 3.1314\n",
      "Epoch 8/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.4866 - loss: 2.9703 - val_accuracy: 0.2747 - val_loss: 3.0901\n",
      "Epoch 9/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.4930 - loss: 2.9134 - val_accuracy: 0.2644 - val_loss: 3.0474\n",
      "Epoch 10/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.4880 - loss: 2.8635 - val_accuracy: 0.2533 - val_loss: 3.0113\n",
      "Epoch 11/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.4996 - loss: 2.8117 - val_accuracy: 0.2430 - val_loss: 2.9732\n",
      "Epoch 12/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5071 - loss: 2.7554 - val_accuracy: 0.2349 - val_loss: 2.9334\n",
      "Epoch 13/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5313 - loss: 2.6994 - val_accuracy: 0.2245 - val_loss: 2.8990\n",
      "Epoch 14/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5207 - loss: 2.6583 - val_accuracy: 0.2223 - val_loss: 2.8632\n",
      "Epoch 15/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5290 - loss: 2.6052 - val_accuracy: 0.2179 - val_loss: 2.8274\n",
      "Epoch 16/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5346 - loss: 2.5578 - val_accuracy: 0.2149 - val_loss: 2.7910\n",
      "Epoch 17/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5375 - loss: 2.5077 - val_accuracy: 0.2105 - val_loss: 2.7591\n",
      "Epoch 18/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5467 - loss: 2.4704 - val_accuracy: 0.2053 - val_loss: 2.7257\n",
      "Epoch 19/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5388 - loss: 2.4287 - val_accuracy: 0.2053 - val_loss: 2.6934\n",
      "Epoch 20/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5559 - loss: 2.3809 - val_accuracy: 0.1979 - val_loss: 2.6649\n",
      "Epoch 21/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5489 - loss: 2.3448 - val_accuracy: 0.1950 - val_loss: 2.6359\n",
      "Epoch 22/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5571 - loss: 2.3033 - val_accuracy: 0.1972 - val_loss: 2.6017\n",
      "Epoch 23/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5569 - loss: 2.2698 - val_accuracy: 0.1891 - val_loss: 2.5780\n",
      "Epoch 24/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5619 - loss: 2.2320 - val_accuracy: 0.1920 - val_loss: 2.5530\n",
      "Epoch 25/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5561 - loss: 2.1926 - val_accuracy: 0.1891 - val_loss: 2.5243\n",
      "Epoch 26/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5701 - loss: 2.1540 - val_accuracy: 0.1846 - val_loss: 2.5001\n",
      "Epoch 27/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5593 - loss: 2.1270 - val_accuracy: 0.1832 - val_loss: 2.4790\n",
      "Epoch 28/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5793 - loss: 2.0829 - val_accuracy: 0.1846 - val_loss: 2.4522\n",
      "Epoch 29/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5714 - loss: 2.0566 - val_accuracy: 0.1802 - val_loss: 2.4271\n",
      "Epoch 30/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5677 - loss: 2.0335 - val_accuracy: 0.1795 - val_loss: 2.4063\n",
      "Epoch 31/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5650 - loss: 1.9973 - val_accuracy: 0.1743 - val_loss: 2.3813\n",
      "Epoch 32/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5686 - loss: 1.9658 - val_accuracy: 0.1743 - val_loss: 2.3569\n",
      "Epoch 33/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5894 - loss: 1.9262 - val_accuracy: 0.1662 - val_loss: 2.3415\n",
      "Epoch 34/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5826 - loss: 1.9084 - val_accuracy: 0.1662 - val_loss: 2.3245\n",
      "Epoch 35/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5837 - loss: 1.8749 - val_accuracy: 0.1699 - val_loss: 2.3012\n",
      "Epoch 36/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5853 - loss: 1.8532 - val_accuracy: 0.1640 - val_loss: 2.2785\n",
      "Epoch 37/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5872 - loss: 1.8230 - val_accuracy: 0.1566 - val_loss: 2.2601\n",
      "Epoch 38/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5757 - loss: 1.8086 - val_accuracy: 0.1484 - val_loss: 2.2436\n",
      "Epoch 39/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5852 - loss: 1.7777 - val_accuracy: 0.1448 - val_loss: 2.2296\n",
      "Epoch 40/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5847 - loss: 1.7546 - val_accuracy: 0.1455 - val_loss: 2.2082\n",
      "Epoch 41/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5860 - loss: 1.7325 - val_accuracy: 0.1440 - val_loss: 2.1914\n",
      "Epoch 42/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5914 - loss: 1.7143 - val_accuracy: 0.1411 - val_loss: 2.1763\n",
      "Epoch 43/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5958 - loss: 1.6947 - val_accuracy: 0.1337 - val_loss: 2.1668\n",
      "Epoch 44/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6039 - loss: 1.6597 - val_accuracy: 0.1307 - val_loss: 2.1523\n",
      "Epoch 45/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5893 - loss: 1.6491 - val_accuracy: 0.1337 - val_loss: 2.1326\n",
      "Epoch 46/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5905 - loss: 1.6246 - val_accuracy: 0.1329 - val_loss: 2.1179\n",
      "Epoch 47/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6119 - loss: 1.5907 - val_accuracy: 0.1270 - val_loss: 2.1137\n",
      "Epoch 48/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5998 - loss: 1.5837 - val_accuracy: 0.1263 - val_loss: 2.0966\n",
      "Epoch 49/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5968 - loss: 1.5641 - val_accuracy: 0.1226 - val_loss: 2.0862\n",
      "Epoch 50/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5996 - loss: 1.5468 - val_accuracy: 0.1233 - val_loss: 2.0707\n",
      "Epoch 51/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.6036 - loss: 1.5343 - val_accuracy: 0.1226 - val_loss: 2.0592\n",
      "Epoch 52/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6021 - loss: 1.5047 - val_accuracy: 0.1211 - val_loss: 2.0478\n",
      "Epoch 53/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6064 - loss: 1.4920 - val_accuracy: 0.1204 - val_loss: 2.0387\n",
      "Epoch 54/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5907 - loss: 1.4794 - val_accuracy: 0.1182 - val_loss: 2.0316\n",
      "Epoch 55/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6055 - loss: 1.4650 - val_accuracy: 0.1160 - val_loss: 2.0185\n",
      "Epoch 56/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5982 - loss: 1.4550 - val_accuracy: 0.1152 - val_loss: 2.0052\n",
      "Epoch 57/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6063 - loss: 1.4354 - val_accuracy: 0.1160 - val_loss: 2.0013\n",
      "Epoch 58/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6109 - loss: 1.4150 - val_accuracy: 0.1174 - val_loss: 1.9930\n",
      "Epoch 59/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6040 - loss: 1.4057 - val_accuracy: 0.1167 - val_loss: 1.9765\n",
      "Epoch 60/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5882 - loss: 1.4028 - val_accuracy: 0.1137 - val_loss: 1.9691\n",
      "Epoch 61/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6117 - loss: 1.3758 - val_accuracy: 0.1071 - val_loss: 1.9613\n",
      "Epoch 62/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6123 - loss: 1.3625 - val_accuracy: 0.1100 - val_loss: 1.9528\n",
      "Epoch 63/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6083 - loss: 1.3516 - val_accuracy: 0.1108 - val_loss: 1.9413\n",
      "Epoch 64/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6110 - loss: 1.3342 - val_accuracy: 0.1093 - val_loss: 1.9339\n",
      "Epoch 65/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6199 - loss: 1.3237 - val_accuracy: 0.1049 - val_loss: 1.9312\n",
      "Epoch 66/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6134 - loss: 1.3208 - val_accuracy: 0.1056 - val_loss: 1.9222\n",
      "Epoch 67/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6160 - loss: 1.3080 - val_accuracy: 0.0997 - val_loss: 1.9216\n",
      "Epoch 68/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6160 - loss: 1.2916 - val_accuracy: 0.1049 - val_loss: 1.9113\n",
      "Epoch 69/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6189 - loss: 1.2843 - val_accuracy: 0.1071 - val_loss: 1.9012\n",
      "Epoch 70/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6170 - loss: 1.2730 - val_accuracy: 0.1034 - val_loss: 1.8979\n",
      "Epoch 71/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6222 - loss: 1.2623 - val_accuracy: 0.0982 - val_loss: 1.8997\n",
      "Epoch 72/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6260 - loss: 1.2518 - val_accuracy: 0.0982 - val_loss: 1.8918\n",
      "Epoch 73/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6265 - loss: 1.2390 - val_accuracy: 0.0953 - val_loss: 1.8950\n",
      "Epoch 74/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6095 - loss: 1.2355 - val_accuracy: 0.0990 - val_loss: 1.8786\n",
      "Epoch 75/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6169 - loss: 1.2217 - val_accuracy: 0.0990 - val_loss: 1.8713\n",
      "Epoch 76/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6244 - loss: 1.2121 - val_accuracy: 0.0975 - val_loss: 1.8716\n",
      "Epoch 77/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6193 - loss: 1.2116 - val_accuracy: 0.0968 - val_loss: 1.8669\n",
      "Epoch 78/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6092 - loss: 1.2022 - val_accuracy: 0.0968 - val_loss: 1.8642\n",
      "Epoch 79/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6230 - loss: 1.1967 - val_accuracy: 0.0990 - val_loss: 1.8544\n",
      "Epoch 80/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6239 - loss: 1.1869 - val_accuracy: 0.0931 - val_loss: 1.8525\n",
      "Epoch 81/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6184 - loss: 1.1765 - val_accuracy: 0.0990 - val_loss: 1.8485\n",
      "Epoch 82/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6207 - loss: 1.1691 - val_accuracy: 0.0953 - val_loss: 1.8523\n",
      "Epoch 83/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6272 - loss: 1.1628 - val_accuracy: 0.0938 - val_loss: 1.8419\n",
      "Epoch 84/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6189 - loss: 1.1592 - val_accuracy: 0.0960 - val_loss: 1.8383\n",
      "Epoch 85/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6224 - loss: 1.1450 - val_accuracy: 0.0945 - val_loss: 1.8368\n",
      "Epoch 86/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6242 - loss: 1.1328 - val_accuracy: 0.0938 - val_loss: 1.8360\n",
      "Epoch 87/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6229 - loss: 1.1335 - val_accuracy: 0.0953 - val_loss: 1.8294\n",
      "Epoch 88/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6161 - loss: 1.1293 - val_accuracy: 0.0975 - val_loss: 1.8252\n",
      "Epoch 89/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6328 - loss: 1.1206 - val_accuracy: 0.0901 - val_loss: 1.8361\n",
      "Epoch 90/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6327 - loss: 1.1110 - val_accuracy: 0.0960 - val_loss: 1.8242\n",
      "Epoch 91/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6273 - loss: 1.1101 - val_accuracy: 0.0923 - val_loss: 1.8227\n",
      "Epoch 92/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6369 - loss: 1.0940 - val_accuracy: 0.0931 - val_loss: 1.8220\n",
      "Epoch 93/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6225 - loss: 1.1028 - val_accuracy: 0.0953 - val_loss: 1.8196\n",
      "Epoch 94/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6233 - loss: 1.0938 - val_accuracy: 0.0894 - val_loss: 1.8170\n",
      "Epoch 95/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6292 - loss: 1.0904 - val_accuracy: 0.0894 - val_loss: 1.8140\n",
      "Epoch 96/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6289 - loss: 1.0818 - val_accuracy: 0.0886 - val_loss: 1.8102\n",
      "Epoch 97/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6229 - loss: 1.0793 - val_accuracy: 0.0886 - val_loss: 1.8148\n",
      "Epoch 98/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6221 - loss: 1.0724 - val_accuracy: 0.0849 - val_loss: 1.8123\n",
      "Epoch 99/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6305 - loss: 1.0633 - val_accuracy: 0.0857 - val_loss: 1.8120\n",
      "Epoch 100/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6275 - loss: 1.0633 - val_accuracy: 0.0894 - val_loss: 1.8050\n",
      "Epoch 101/2000\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6375 - loss: 1.0531 - val_accuracy: 0.0886 - val_loss: 1.7997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m43/43\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.0820 - loss: 1.8760     \n",
      "Fold 1: Accuracy = 0.0010667979950085282\n",
      "Fold 2: Accuracy = 0.10495650768280029\n",
      "Fold 3: Accuracy = 0.0\n",
      "Fold 4: Accuracy = 0.17577548325061798\n",
      "Fold 5: Accuracy = 0.4025110900402069\n",
      "Fold 6: Accuracy = 0.2370753288269043\n",
      "Fold 7: Accuracy = 0.1277695745229721\n",
      "Fold 8: Accuracy = 0.008493352681398392\n",
      "Fold 9: Accuracy = 0.053175777196884155\n",
      "Fold 10: Accuracy = 0.08862629532814026\n",
      "Average Accuracy: 0.11994502075249329\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold_index, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Chia thành tập huấn luyện và tập kiểm tra\n",
    "    time_steps = 655\n",
    "\n",
    "    # Chuẩn bị đầu vào và đầu ra cho mô hình Bi-LSTM\n",
    "    def prepare_data(data, labels, time_steps):\n",
    "        X = []\n",
    "        y = []\n",
    "        for j in range(len(data)):\n",
    "            for i in range(data.shape[1] - time_steps):\n",
    "                X.append(data[j, i:i+time_steps].reshape(1, time_steps))  # Reshape input data\n",
    "                y.append(labels[j])\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    X_train, y_train = prepare_data(X_train, y_train, time_steps)\n",
    "    X_test, y_test = prepare_data(X_test, y_test, time_steps)\n",
    "\n",
    "    # Xây dựng mô hình Bi-LSTM\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units=16, activation='relu', kernel_regularizer=regularizers.l2(0.01)), input_shape=(1, time_steps)))\n",
    "    # model.add(Bidirectional(LSTM(units=16, activation='relu'), input_shape=(time_steps, n_features)))\n",
    "    model.add(Dropout(0.1))\n",
    "    # model.add(Bidirectional(LSTM(units=16, activation='relu', kernel_regularizer=regularizers.l2(0.01)), input_shape=(1, time_steps)))\n",
    "    model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "    #learning rate\n",
    "    lr = 0.0001\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "    # Biên dịch mô hình\n",
    "    model.compile(optimizer=optimizer , loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Đặt callbacks để dừng sau 10 epochs\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=100)\n",
    "\n",
    "    # Huấn luyện mô hình và lưu history\n",
    "    history = model.fit(X_train, y_train, epochs=2000, batch_size=512, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "    # Lưu mô hình\n",
    "    model_filename = f\"BiLSTM_Brainwave_{fold_index}_accuracy_{history.history['val_accuracy'][-1]*100:.2f}.h5\"\n",
    "    model.save(os.path.join(model_dir, model_filename))\n",
    "    model_filenames.append(model_filename)\n",
    "\n",
    "    # Đánh giá mô hình trên tập kiểm tra\n",
    "    _, accuracy = model.evaluate(X_test, y_test)\n",
    "    fold_scores.append(accuracy)\n",
    "\n",
    "    # Vẽ đồ thị loss và accuracy\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper right')\n",
    "    plt.savefig(f\"{model_dir}/{os.path.splitext(model_filename)[0]}_loss.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='lower right')\n",
    "    plt.savefig(f\"{model_dir}/{os.path.splitext(model_filename)[0]}_accuracy.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    # Lưu accuracy và loss của fold hiện tại vào DataFrame\n",
    "    for epoch, (train_loss, test_loss, train_accuracy, test_accuracy) in enumerate(zip(\n",
    "        history.history['loss'],\n",
    "        history.history['val_loss'],\n",
    "        history.history['accuracy'],\n",
    "        history.history['val_accuracy']\n",
    "    ), 1):\n",
    "        history_df = pd.concat([history_df, pd.DataFrame({\n",
    "            'fold': [fold_index],\n",
    "            'epoch': [epoch],\n",
    "            'train_loss': [train_loss],\n",
    "            'test_loss': [test_loss],\n",
    "            'train_accuracy': [train_accuracy],\n",
    "            'test_accuracy': [test_accuracy]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "    # Lưu thông tin của fold hiện tại vào file txt\n",
    "    with open(f'{model_dir}/{os.path.splitext(model_filename)[0]}.txt', 'w') as file:\n",
    "        file.write(f\"Train Loss: {history.history['loss'][-1]}\\n\")\n",
    "        file.write(f\"Train Accuracy: {history.history['accuracy'][-1]}\\n\")\n",
    "        file.write(f\"Validation Loss: {history.history['val_loss'][-1]}\\n\")\n",
    "        file.write(f\"Validation Accuracy: {history.history['val_accuracy'][-1]}\\n\")\n",
    "    break\n",
    "# In kết quả\n",
    "for i, score in enumerate(fold_scores, 1):\n",
    "    print(f\"Fold {i}: Accuracy = {score}\")\n",
    "\n",
    "print(\"Average Accuracy:\", np.mean(fold_scores))\n",
    "\n",
    "# Lưu DataFrame vào file CSV\n",
    "history_df.to_csv('history_bi_lstm.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T10:54:20.830836Z",
     "start_time": "2024-05-21T10:54:07.868510Z"
    }
   },
   "id": "fd0e7bc043b0b434",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T05:28:02.366376Z",
     "start_time": "2024-05-11T05:28:02.363854Z"
    }
   },
   "id": "424a250136a03ee1",
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
